{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b5c0d2440b3e4995a794ded565213150","deepnote_cell_type":"markdown"},"source":["<h1><center>Laboratorio 9: Optimización de modelos 💯</center></h1>\n","\n","<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos</strong></center>"]},{"cell_type":"markdown","metadata":{"cell_id":"bfb94b9656f145ad83e81b75d218cb70","deepnote_cell_type":"markdown"},"source":["### Cuerpo Docente:\n","\n","- Profesor: Ignacio Meza, Gabriel Iturra\n","- Auxiliar: Sebastián Tinoco\n","- Ayudante: Arturo Lazcano, Angelo Muñoz"]},{"cell_type":"markdown","metadata":{"cell_id":"b1b537fdd27c43909a49d3476ce64d91","deepnote_cell_type":"markdown"},"source":["### Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados\n","\n","- Nombre de alumno 1: Nicolás Acevedo\n","- Nombre de alumno 2: Fabiola Pizarro\n"]},{"cell_type":"markdown","metadata":{"cell_id":"b7dbdd30ab544cb8a8afe00648a586ae","deepnote_cell_type":"markdown"},"source":["## Temas a tratar\n","\n","- Predicción de demanda usando `xgboost`\n","- Búsqueda del modelo óptimo de clasificación usando `optuna`\n","- Uso de pipelines.\n","\n","## Reglas:\n","\n","- **Grupos de 2 personas**\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n","- Prohibidas las copias. \n","- Pueden usar cualquer material del curso que estimen conveniente.\n","\n","### Objetivos principales del laboratorio\n","\n","- Optimizar modelos usando `optuna`\n","- Recurrir a técnicas de *prunning*\n","- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n","- Fijar un pipeline con un modelo base que luego se irá optimizando.\n","\n","El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."]},{"cell_type":"markdown","metadata":{"cell_id":"f38c8342f5164aa992a97488dd5590bf","deepnote_cell_type":"markdown"},"source":["### **Link de repositorio de GitHub:** `https://github.com/nicoacevedor/MDS7202`"]},{"cell_type":"markdown","metadata":{"cell_id":"f1c73babb7f74af588a4fa6ae14829e0","deepnote_cell_type":"markdown"},"source":["# Importamos librerias útiles"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"51afe4d2df42442b9e5402ffece60ead","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4957,"execution_start":1699544354044,"source_hash":null},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from datetime import datetime\n","import joblib\n","\n","import numpy as np\n","import pandas as pd\n","import optuna\n","from optuna.samplers import TPESampler\n","from pandas.api.types import is_datetime64_any_dtype as is_datetime\n","from sklearn.compose import ColumnTransformer\n","from sklearn.dummy import DummyRegressor\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n","import xgboost as xgb"]},{"cell_type":"markdown","metadata":{"cell_id":"44d227389a734ac59189c5e0005bc68a","deepnote_cell_type":"markdown"},"source":["# 1. El emprendimiento de Fiu\n","\n","Tras liderar de manera exitosa la implementación de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corpóreo **Fiu** se anima y decide levantar su propio negocio de consultoría en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Como usted tuvo un rendimiento sobresaliente en el proyecto de caracterización de datos, Fiu lo contrata como *data scientist* de su emprendimiento.\n","\n","Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n","\n","Para comenzar, cargue el dataset señalado y visualice a través de un `.head` los atributos que posee el dataset.\n","\n","<i><p align=\"center\">Fiu siendo felicitado por su excelente desempeño en el proyecto de caracterización de datos</p></i>\n","<p align=\"center\">\n","  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n","</p>"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"2f9c82d204b14515ad27ae07e0b77702","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":92,"execution_start":1699544359006,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7456 entries, 0 to 7455\n","Data columns (total 12 columns):\n"," #   Column     Non-Null Count  Dtype         \n","---  ------     --------------  -----         \n"," 0   id         7456 non-null   int32         \n"," 1   date       7456 non-null   datetime64[ns]\n"," 2   city       7456 non-null   category      \n"," 3   lat        7456 non-null   float64       \n"," 4   long       7456 non-null   float64       \n"," 5   pop        7456 non-null   int32         \n"," 6   shop       7456 non-null   category      \n"," 7   brand      7456 non-null   category      \n"," 8   container  7456 non-null   category      \n"," 9   capacity   7456 non-null   category      \n"," 10  price      7456 non-null   float64       \n"," 11  quantity   7456 non-null   int32         \n","dtypes: category(5), datetime64[ns](1), float64(3), int32(3)\n","memory usage: 357.8 KB\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Rocky\\AppData\\Local\\Temp\\ipykernel_14396\\2241364177.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = df.astype(df_types)\n"]}],"source":["df = pd.read_csv('sales.csv')\n","df_types = {\n","    'id': int,\n","    'date': 'datetime64[ns]',\n","    'city': 'category',\n","    'lat': float,\n","    'long': float,\n","    'pop': int,\n","    'shop': 'category',\n","    'brand': 'category',\n","    'container': 'category',\n","    'capacity': 'category',\n","    'price': float,\n","    'quantity': int\n","}\n","df = df.astype(df_types)\n","df.info()\n"]},{"cell_type":"markdown","metadata":{"cell_id":"b50db6f2cb804932ae3f9e5748a6ea61","deepnote_cell_type":"markdown"},"source":["## 1.1 Generando un Baseline (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n","</p>\n","\n","Antes de entrenar un algoritmo, usted recuerda los apuntes de su magíster en ciencia de datos y recuerda que debe seguir una serie de *buenas prácticas* para entrenar correcta y debidamente su modelo. Después de un par de vueltas, llega a las siguientes tareas:\n","\n","1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad.\n","2. Implemente un `FunctionTransformer` para extraer el día, mes y año de la variable `date`. Guarde estas variables en el formato categorical de pandas.\n","3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos numéricos y categóricos. Use `OneHotEncoder` para las variables categóricas.\n","4. Guarde los pasos anteriores en un `Pipeline`, dejando como último paso el regresor `DummyRegressor` para generar predicciones en base a promedios.\n","5. Entrene el pipeline anterior y reporte la métrica `mean_absolute_error` sobre los datos de validación. ¿Cómo se interpreta esta métrica para el contexto del negocio?\n","6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los parámetros por default**. ¿Cómo cambia el MAE al implementar este algoritmo? ¿Es mejor o peor que el `DummyRegressor`?\n","7. Guarde ambos modelos en un archivo .pkl (uno cada uno)"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"1482c992d9494e5582b23dbd3431dbfd","deepnote_cell_type":"code"},"outputs":[],"source":["gen = np.random.default_rng(seed=42)\n","data = pd.DataFrame(gen.permutation(df), columns=df.columns)\n","data = data.astype(df_types)\n","n = data.shape[0]\n","\n","train_size, val_size = int(0.7*n), int(0.2*n)\n","train_data = data[:train_size]\n","validation_data = data[train_size:train_size+val_size]\n","test_data = data[train_size+val_size:]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def datetime_to_categorical(df: pd.DataFrame):\n","    df_in = df.copy()\n","    datetime_column = ''\n","    for col in df.columns:\n","        if is_datetime(df[col]):\n","            datetime_column = col\n","    if datetime_column == '':\n","        raise ValueError(\"Los datos no poseen ninguna columna con formato fecha\")\n","\n","    df_in['day'] = df_in[datetime_column].dt.day\n","    df_in['day'] = df_in['day'].astype('category')\n","    df_in['month'] = df_in[datetime_column].dt.month\n","    df_in['month'] = df_in['month'].astype('category')\n","    df_in['year'] = df_in[datetime_column].dt.year\n","    df_in['year'] = df_in['year'].astype('category')\n","    df_in.drop([datetime_column], axis=1, inplace=True)\n","    return df_in"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["numeric_cols = ['id', 'lat', 'long', 'pop', 'price', 'quantity']\n","categorical_cols = list(set(df.columns) - (set(numeric_cols).union({'date'})))\n","categorical_cols = list(set(categorical_cols) | set(['day', 'month', 'year']))\n","\n","transformer = FunctionTransformer(datetime_to_categorical)\n","\n","scaler = ColumnTransformer([\n","    (\"NumericScaler\", MinMaxScaler(), numeric_cols),\n","    (\"CategoricalEncoder\", OneHotEncoder(sparse_output=False), categorical_cols)\n","], remainder=\"drop\", verbose_feature_names_out=False)\n","scaler.set_output(transform='pandas')\n","\n","pipeline_dummy = Pipeline([\n","    ('Transformer', transformer),\n","    ('Scaler', scaler),\n","    ('Regressor', DummyRegressor())\n","])\n","\n","pipeline_xgb = Pipeline([\n","    ('Transformer', transformer),\n","    ('Scaler', scaler),\n","    ('Regressor', xgb.XGBRegressor())\n","])\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El error absoluto medio es de 13439.757\n"]}],"source":["X_train = train_data[list(set(data.columns) - set('quantity'))]\n","X_validation = validation_data[list(set(data.columns) - set('quantity'))]\n","X_test = test_data[list(set(data.columns) - set('quantity'))]\n","y_train = train_data['quantity']\n","y_validation = validation_data['quantity']\n","y_test = test_data['quantity']\n","\n","pipeline_dummy.fit(X=X_train, y=y_train)\n","joblib.dump(pipeline_dummy, \"pipeline_dummy.pkl\")\n","y_pred_dummy = pipeline_dummy.predict(X_validation)\n","\n","print(f\"El error absoluto medio es de {mean_absolute_error(y_validation, y_pred_dummy):.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["Al ser un valor tan alto, esto nos dice que la predicción no es buena. En el contexto de las ventas, esto indica que las ventas tienen muchos valores distintos, y que no son similares a la media de todas las ventas. Esto tiene sentido ya que la cantidad de ventas depende por lo menos del país, del producto y del precio."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El error absoluto medio es de 150.760\n"]}],"source":["pipeline_xgb.fit(X=X_train, y=y_train)\n","y_pred_xgb = pipeline_xgb.predict(X_validation)\n","joblib.dump(pipeline_xgb, \"pipeline_xgb.pkl\")\n","print(f\"El error absoluto medio es de {mean_absolute_error(y_validation, y_pred_xgb):.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["Este resultado es mucho mejor, ya que el error absoluto medio es un 1% del valor anterior. Esto indica que la predicción hecha por XGBRegressor es mucho más cercana a la realidad que solo tomar la media de los datos."]},{"cell_type":"markdown","metadata":{"cell_id":"7e17e46063774ec28226fe300d42ffe0","deepnote_cell_type":"markdown"},"source":["## 1.2 Forzando relaciones entre parámetros con XGBoost (1.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n","</p>\n","\n","Un colega aficionado a la economía le *sopla* que la demanda guarda una relación inversa con el precio del producto. Motivado para impresionar al querido corpóreo, se propone hacer uso de esta información para mejorar su modelo.\n","\n","Vuelva a entrenar el `Pipeline`, pero esta vez forzando una relación monótona negativa entre el precio y la cantidad. Luego, vuelva a reportar el `MAE` sobre el conjunto de validación. ¿Cómo cambia el error al incluir esta relación? ¿Tenía razón su amigo?\n","\n","Nuevamente, guarde su modelo en un archivo .pkl\n","\n","Nota: Para realizar esta parte, debe apoyarse en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentación</a>.\n","\n","Hint: Para implementar el constraint, se le sugiere hacerlo especificando el nombre de la variable. De ser así, probablemente le sea útil **mantener el formato de pandas** antes del step de entrenamiento."]},{"cell_type":"code","execution_count":8,"metadata":{"cell_id":"f469f3b572be434191d2d5c3f11b20d2","deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":["El error absoluto medio es de 151.987\n"]}],"source":["pipeline_xgb_constraint = Pipeline([\n","    ('Transformer', transformer),\n","    ('Scaler', scaler),\n","    ('Regressor', xgb.XGBRegressor(monotone_constraints={'price': -1}))\n","])\n","pipeline_xgb_constraint.fit(X=X_train, y=y_train)\n","joblib.dump(pipeline_xgb_constraint, \"pipeline_xgb_constraint.pkl\")\n","y_pred_constraint = pipeline_xgb_constraint.predict(X_validation)\n","print(f\"El error absoluto medio es de {mean_absolute_error(y_validation, y_pred_constraint):.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["El error aumenta un poco, no mucho pero aumenta. Esto puede deberse a que anteriormente el modelo ya aprendió la relación inversa entre el precio y el producto, por lo que la variación es poca. Además, si bien existe esta relación inversa, eso no considera otros factores como el precio por país, que aunque este aumente, puede que en proporción el producto sea más barato, por lo que en esa situación la relación ya no es completamente inversa.\n","\n","Por lo tanto, el amigo no tiene toda la razón."]},{"cell_type":"markdown","metadata":{"cell_id":"e59ef80ed20b4de8921f24da74e87374","deepnote_cell_type":"markdown"},"source":["## 1.3 Optimización de Hiperparámetros con Optuna (2.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n","</p>\n","\n","Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun más* su modelo. En particular, le comenta de la optimización de hiperparámetros con metodologías bayesianas a través del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n","\n","A partir de la mejor configuración obtenida en la sección anterior, utilice `optuna` para optimizar sus hiperparámetros. En particular, se le pide:\n","\n","- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n","- Utilice `TPESampler` como método de muestreo\n","- De `XGBRegressor`, optimice los siguientes hiperparámetros:\n","    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n","    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n","    - `max_depth` buscando valores enteros en el rango (3, 10)\n","    - `max_leaves` buscando valores enteros en el rango (0, 100)\n","    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n","    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n","    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n","- De `OneHotEncoder`, optimice el hiperparámetro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n","- Explique cada hiperparámetro y su rol en el modelo. ¿Hacen sentido los rangos de optimización indicados?\n","- Fije el tiempo de entrenamiento a 5 minutos\n","- Reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto?\n","- Guardar su modelo en un archivo .pkl"]},{"cell_type":"markdown","metadata":{},"source":["Los hiperparámetros del `XGBRegressor` son los siguientes:\n","- `learning_rate`: Factor de aprendizaje del modelo\n","- `n_estimators`: Número de árboles generados\n","- `max_depth`: Máxima profundidad de cada árbol\n","- `max_leaves`: Número máximo de hojas de cada árbol\n","- `min_child_weight`: Umbral para el cual un nodo se deja de dividir si la cantidad de datos baja de este\n","- `reg_alpha`: Factor de regularización para dimensiones altas\n","- `reg_lambda`: Factor de regularización para reducir overfitting\n","\n","El hiperparámetro del `OneHotEncoder`\n","- `min_frequency`: Mínima frecuencia relativa para una etiqueta ser considerada categoría"]},{"cell_type":"code","execution_count":9,"metadata":{"cell_id":"de5914621cc64cb0b1bacb9ff565a97e","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["Best trial: 872. Best value: 126.557:  100%|██████████| 05:00/05:00\n"]}],"source":["optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","random_seed = 42\n","\n","study = optuna.create_study(\n","    sampler=TPESampler(seed=random_seed),\n","    direction='minimize',\n","    study_name=\"pipeline\"\n",")\n","\n","def objective(trial: optuna.Trial, data, target, validation, val_target, random_seed=42):\n","    regressor_params = {\n","        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n","        'n_estimators': trial.suggest_int('n_estimators', 50, 100),\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'max_leaves': trial.suggest_int('max_leaves', 0, 100),\n","        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n","        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n","        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)\n","    }\n","    numeric_cols = ['id', 'lat', 'long', 'pop', 'price', 'quantity']\n","    categorical_cols = list(set(data.columns) - (set(numeric_cols).union({'date'})))\n","    categorical_cols = list(set(categorical_cols) | set(['day', 'month', 'year']))\n","\n","    transformer = FunctionTransformer(datetime_to_categorical)\n","\n","    min_frequency = trial.suggest_float('min_frequency', 0, 1)\n","    scaler = ColumnTransformer([\n","        (\"NumericScaler\", MinMaxScaler(), numeric_cols),\n","        (\"CategoricalEncoder\", OneHotEncoder(sparse_output=False, min_frequency=min_frequency), categorical_cols)\n","    ], remainder=\"drop\", verbose_feature_names_out=False)\n","    scaler.set_output(transform='pandas')\n","\n","    regressor = xgb.XGBRegressor(**regressor_params)\n","\n","    pipeline = Pipeline([\n","        ('Transformer', transformer),\n","        ('Scaler', scaler),\n","        ('Regressor', regressor), \n","    ])\n","\n","    pipeline.fit(X=data, y=target)\n","    y_pred = pipeline.predict(X=validation)\n","    return mean_absolute_error(val_target, y_pred)\n","\n","\n","study.optimize(\n","    lambda trial: objective(trial, X_train, y_train, X_validation, y_validation),\n","    timeout=5*60,\n","    show_progress_bar=True\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Número de trials: 1072\n","MAE: 126.557\n","\n","Mejores parámetros:\n","--------------------\n","learning_rate: 0.082\n","n_estimators: 97.000\n","max_depth: 5.000\n","max_leaves: 25.000\n","min_child_weight: 1.000\n","reg_alpha: 0.149\n","reg_lambda: 0.111\n","min_frequency: 0.467\n"]}],"source":["min_frequency_opt = study.best_params.pop('min_frequency')\n","\n","scaler = ColumnTransformer([\n","    (\"NumericScaler\", MinMaxScaler(), numeric_cols),\n","    (\"CategoricalEncoder\", OneHotEncoder(sparse_output=False, min_frequency=min_frequency_opt), categorical_cols)\n","], remainder=\"drop\", verbose_feature_names_out=False)\n","scaler.set_output(transform='pandas')\n","\n","optimized_pipeline = Pipeline([\n","    ('Transformer', transformer),\n","    ('Scaler', scaler),\n","    ('Regressor', xgb.XGBRegressor(random_seed=42, **study.best_params))\n","])\n","joblib.dump(optimized_pipeline, \"optimized_pipeline.pkl\")\n","\n","print(f\"Número de trials: {len(study.trials)}\")\n","print(f\"MAE: {study.best_value:.3f}\")\n","print(\"\\nMejores parámetros:\\n--------------------\")\n","for key, value in study.best_params.items():\n","    print(f\"{key}: {value:.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["El `MAE` es menor al encontrado en la sección anterior, lo que se debe a que se está trabajando con valores mucho más óptimos de los hiperparámetros, en cambio antes se trabajaba con los valores por defecto que, si bien dan un resultado más o menos bueno, no es el mejor. Por lo tanto, al haber reducido el `MAE`, vemos que el nuevo modelo optimizado es mejor que el de la sección anterior."]},{"cell_type":"markdown","metadata":{"cell_id":"5195ccfc37e044ad9453f6eb2754f631","deepnote_cell_type":"markdown"},"source":["## 1.4 Optimización de Hiperparámetros con Optuna y Prunners (1.7)\n","\n","<p align=\"center\">\n","  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n","</p>\n","\n","Después de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en sí mismo. Después de leer un par de post de personas de dudosa reputación en la *deepweb*, usted llega a la conclusión que puede cumplir este objetivo mediante la implementación de **Prunning**.\n","\n","Vuelva a optimizar los mismos hiperparámetros que la sección pasada, pero esta vez utilizando **Prunning** en la optimización. En particular, usted debe:\n","\n","- Responder: ¿Qué es prunning? ¿De qué forma debería impactar en el entrenamiento?\n","- Utilizar `optuna.integration.XGBoostPruningCallback` como método de **Prunning**\n","- Fijar nuevamente el tiempo de entrenamiento a 5 minutos\n","- Reportar el número de *trials*, el `MAE` y los mejores hiperparámetros encontrados. ¿Cómo cambian sus resultados con respecto a la sección anterior? ¿A qué se puede deber esto?\n","- Guardar su modelo en un archivo .pkl\n","\n","Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n","\n","```\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","```\n","\n","De implementar la opción anterior, pueden especificar `show_progress_bar = True` en el método `optimize` para *más sabor*.\n","\n","Hint: Si quieren especificar parámetros del método .fit() del modelo a través del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n","\n","Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementación"]},{"cell_type":"code","execution_count":20,"metadata":{"cell_id":"eeaa967cd8f6426d8c54f276c17dce79","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["   0%|          | 00:00/05:00"]},{"name":"stdout","output_type":"stream","text":["[0]\tvalidation_0-mae:12929.58351\n","[1]\tvalidation_0-mae:12439.61955\n","[2]\tvalidation_0-mae:11967.95412\n","[3]\tvalidation_0-mae:11514.05199\n","[4]\tvalidation_0-mae:11076.83867\n","[5]\tvalidation_0-mae:10656.75833\n","[6]\tvalidation_0-mae:10253.09367\n","[7]\tvalidation_0-mae:9863.58898\n","[8]\tvalidation_0-mae:9490.42122\n","[9]\tvalidation_0-mae:9130.28326\n","[10]\tvalidation_0-mae:8783.58811\n","[11]\tvalidation_0-mae:8451.37023\n","[12]\tvalidation_0-mae:8130.44730\n","[13]\tvalidation_0-mae:7821.96862\n","[14]\tvalidation_0-mae:7525.70140\n","[15]\tvalidation_0-mae:7241.09228\n","[16]\tvalidation_0-mae:6966.15285\n","[17]\tvalidation_0-mae:6702.22867\n","[18]\tvalidation_0-mae:6447.97666\n","[19]\tvalidation_0-mae:6204.14580\n","[20]\tvalidation_0-mae:5969.64566\n","[21]\tvalidation_0-mae:5743.40575\n","[22]\tvalidation_0-mae:5525.83989\n","[23]\tvalidation_0-mae:5316.55916\n","[24]\tvalidation_0-mae:5115.11822\n","[25]\tvalidation_0-mae:4921.75714\n","[26]\tvalidation_0-mae:4735.67670\n","[27]\tvalidation_0-mae:4556.88736\n","[28]\tvalidation_0-mae:4384.83296\n","[29]\tvalidation_0-mae:4219.27736\n","[30]\tvalidation_0-mae:4059.74337\n","[31]\tvalidation_0-mae:3906.56417\n","[32]\tvalidation_0-mae:3758.78135\n","[33]\tvalidation_0-mae:3616.92393\n","[34]\tvalidation_0-mae:3480.21269\n","[35]\tvalidation_0-mae:3348.98235\n","[36]\tvalidation_0-mae:3222.76328\n","[37]\tvalidation_0-mae:3101.00014\n","[38]\tvalidation_0-mae:2984.32885\n","[39]\tvalidation_0-mae:2871.76721\n","[40]\tvalidation_0-mae:2763.65600\n","[41]\tvalidation_0-mae:2659.68117\n","[42]\tvalidation_0-mae:2559.60263\n","[43]\tvalidation_0-mae:2463.32860\n","[44]\tvalidation_0-mae:2370.75280\n","[45]\tvalidation_0-mae:2281.53292\n","[46]\tvalidation_0-mae:2195.86869\n","[47]\tvalidation_0-mae:2113.18655\n","[48]\tvalidation_0-mae:2033.64121\n","[49]\tvalidation_0-mae:1957.28130\n","[50]\tvalidation_0-mae:1883.79974\n","[51]\tvalidation_0-mae:1812.96264\n","[52]\tvalidation_0-mae:1744.97940\n","[53]\tvalidation_0-mae:1679.49088\n","[54]\tvalidation_0-mae:1616.54194\n","[55]\tvalidation_0-mae:1556.06630\n","[56]\tvalidation_0-mae:1497.95175\n","[57]\tvalidation_0-mae:1442.00511\n","[58]\tvalidation_0-mae:1388.30914\n","[59]\tvalidation_0-mae:1336.32726\n","[60]\tvalidation_0-mae:1286.63880\n","[61]\tvalidation_0-mae:1238.86014\n","[62]\tvalidation_0-mae:1192.91900\n","[63]\tvalidation_0-mae:1148.58114\n","[64]\tvalidation_0-mae:1106.02023\n","[65]\tvalidation_0-mae:1065.09959\n","[66]\tvalidation_0-mae:1025.44421\n","[67]\tvalidation_0-mae:987.57234\n","[68]\tvalidation_0-mae:951.24061\n","[69]\tvalidation_0-mae:916.03981\n","[70]\tvalidation_0-mae:882.19793\n","[71]\tvalidation_0-mae:849.68559\n","[72]\tvalidation_0-mae:818.55594\n","[73]\tvalidation_0-mae:788.57388\n","[74]\tvalidation_0-mae:759.68036\n","[75]\tvalidation_0-mae:731.88672\n","[76]\tvalidation_0-mae:704.93181\n","[77]\tvalidation_0-mae:679.68319\n","[78]\tvalidation_0-mae:655.34445\n","[79]\tvalidation_0-mae:631.73441\n","[80]\tvalidation_0-mae:608.90672\n","[81]\tvalidation_0-mae:586.95616\n","[82]\tvalidation_0-mae:565.91291\n","[83]\tvalidation_0-mae:546.02105\n","[84]\tvalidation_0-mae:526.40528\n","[85]\tvalidation_0-mae:507.90075\n","[86]\tvalidation_0-mae:489.77556\n","[87]\tvalidation_0-mae:472.57144\n","[88]\tvalidation_0-mae:455.99219\n","[89]\tvalidation_0-mae:440.34026\n","[90]\tvalidation_0-mae:425.03821\n","[91]\tvalidation_0-mae:410.56433\n","[92]\tvalidation_0-mae:396.66370\n","[93]\tvalidation_0-mae:383.21426\n","[94]\tvalidation_0-mae:370.27658\n","[95]\tvalidation_0-mae:357.73191\n","[96]\tvalidation_0-mae:345.96610\n","[97]\tvalidation_0-mae:334.81981\n"]},{"name":"stderr","output_type":"stream","text":["   0%|          | 00:00/05:00"]},{"name":"stdout","output_type":"stream","text":["[W 2023-11-17 10:55:44,531] Trial 0 failed with parameters: {'learning_rate': 0.03807947176588889, 'n_estimators': 98, 'max_depth': 8, 'max_leaves': 60, 'min_child_weight': 1, 'reg_alpha': 0.15599452033620265, 'reg_lambda': 0.05808361216819946, 'min_frequency': 0.8661761457749352} because of the following error: ValueError('Los datos no poseen ninguna columna con formato fecha').\n","Traceback (most recent call last):\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","                      ^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Temp\\ipykernel_14396\\334774914.py\", line 65, in <lambda>\n","    lambda trial: objective(trial, X_train, y_train, X_validation, y_validation),\n","                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Temp\\ipykernel_14396\\334774914.py\", line 60, in objective\n","    y_pred = pipeline.predict(X=validation_scaled)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py\", line 480, in predict\n","    Xt = transform.transform(Xt)\n","         ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n","    data_to_wrap = f(self, X, *args, **kwargs)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 238, in transform\n","    return self._transform(X, func=self.func, kw_args=self.kw_args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 310, in _transform\n","    return func(X, **(kw_args if kw_args else {}))\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Temp\\ipykernel_14396\\2374987663.py\", line 8, in datetime_to_categorical\n","    raise ValueError(\"Los datos no poseen ninguna columna con formato fecha\")\n","ValueError: Los datos no poseen ninguna columna con formato fecha\n","[W 2023-11-17 10:55:44,535] Trial 0 failed with value None.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"ename":"ValueError","evalue":"Los datos no poseen ninguna columna con formato fecha","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Rocky\\Documents\\GitHub\\MDS7202\\lab9\\Lab9.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(X\u001b[39m=\u001b[39mvalidation_scaled)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mean_absolute_error(val_target, y_pred)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mlambda\u001b[39;49;00m trial: objective(trial, X_train, y_train, X_validation, y_validation),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m60\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m )\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n","\u001b[1;32mc:\\Users\\Rocky\\Documents\\GitHub\\MDS7202\\lab9\\Lab9.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(X\u001b[39m=\u001b[39mvalidation_scaled)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mean_absolute_error(val_target, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m trial: objective(trial, X_train, y_train, X_validation, y_validation),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     timeout\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m\u001b[39m*\u001b[39m\u001b[39m60\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     show_progress_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m )\n","\u001b[1;32mc:\\Users\\Rocky\\Documents\\GitHub\\MDS7202\\lab9\\Lab9.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m validation_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(validation_transformed)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m pipeline\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mdata, y\u001b[39m=\u001b[39mtarget, Regressor__eval_set\u001b[39m=\u001b[39m[(validation_scaled, val_target)])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m y_pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mpredict(X\u001b[39m=\u001b[39;49mvalidation_scaled)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mreturn\u001b[39;00m mean_absolute_error(val_target, y_pred)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py:480\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    478\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[0;32m    479\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 480\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[0;32m    481\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:238\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39m    Transformed input.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X, func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, kw_args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkw_args)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:310\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[1;34m(self, X, func, kw_args)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m     func \u001b[39m=\u001b[39m _identity\n\u001b[1;32m--> 310\u001b[0m \u001b[39mreturn\u001b[39;00m func(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(kw_args \u001b[39mif\u001b[39;49;00m kw_args \u001b[39melse\u001b[39;49;00m {}))\n","\u001b[1;32mc:\\Users\\Rocky\\Documents\\GitHub\\MDS7202\\lab9\\Lab9.ipynb Cell 27\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         datetime_column \u001b[39m=\u001b[39m col\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m datetime_column \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLos datos no poseen ninguna columna con formato fecha\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df_in[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_in[datetime_column]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mday\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df_in[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_in[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[1;31mValueError\u001b[0m: Los datos no poseen ninguna columna con formato fecha"]}],"source":["optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","random_seed = 42\n","\n","study = optuna.create_study(\n","    sampler=TPESampler(seed=random_seed),\n","    direction='minimize',\n","    study_name=\"pipeline_pruning\"\n",")\n","\n","def objective(trial: optuna.Trial, data, target, validation, val_target, random_seed=42):\n","    regressor_params = {\n","        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n","        'n_estimators': trial.suggest_int('n_estimators', 50, 100),\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'max_leaves': trial.suggest_int('max_leaves', 0, 100),\n","        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n","        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n","        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)\n","    }\n","        \n","    numeric_cols = ['id', 'lat', 'long', 'pop', 'price', 'quantity']\n","    categorical_cols = list(set(data.columns) - (set(numeric_cols).union({'date'})))\n","    categorical_cols = list(set(categorical_cols) | set(['day', 'month', 'year']))\n","    \n","    transformer = FunctionTransformer(datetime_to_categorical)\n","\n","    min_frequency = trial.suggest_float('min_frequency', 0, 1)\n","    scaler = ColumnTransformer([\n","        (\"NumericScaler\", MinMaxScaler(), numeric_cols),\n","        (\"CategoricalEncoder\", OneHotEncoder(sparse_output=False, min_frequency=min_frequency), categorical_cols)\n","    ], remainder=\"drop\", verbose_feature_names_out=False)\n","    scaler.set_output(transform='pandas')\n","\n","    pruning_callback = optuna.integration.XGBoostPruningCallback(\n","        trial, observation_key=\"validation_0-mae\"\n","    )\n","\n","    regressor = xgb.XGBRegressor(**regressor_params, eval_metric='mae',\n","                                early_stopping_rounds=10,\n","                                callbacks=[pruning_callback])\n","\n","    # Habilitar la opción enable_categorical=True\n","    # regressor.set_params(enable_categorical=True)\n","\n","    pipeline = Pipeline([\n","        ('Transformer', transformer),\n","        ('Scaler', scaler),\n","        ('Regressor', regressor), \n","    ])\n","\n","    # Ajustar el ColumnTransformer con los datos de entrenamiento\n","    data_transformed = transformer.transform(data)\n","    scaler.fit(data_transformed)\n","    # Preprocesamiento de los datos de validación\n","    validation_transformed = transformer.transform(validation)\n","    validation_scaled = scaler.transform(validation_transformed)\n","\n","    pipeline.fit(X=data, y=target, Regressor__eval_set=[(validation_scaled, val_target)])\n","    y_pred = pipeline.predict(X=validation_scaled)\n","    return mean_absolute_error(val_target, y_pred)\n","\n","\n","study.optimize(\n","    lambda trial: objective(trial, X_train, y_train, X_validation, y_validation),\n","    timeout=5*60,\n","    show_progress_bar=True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Prunning permite detener automáticamente las pruebas poco prometedoras en las primeras etapas del entrenamiento de un modelo, en otras palabras, se interrumpe el entrenamiento de un modelo si no muestra un rendimiento prometedor según una métrica específica. Esto debería beneficiar el entrenamiento del modelo porque ayuda a evitar el sobreajuste y mejorar la eficiencia del proceso de búsqueda de hiperparámetros."]},{"cell_type":"markdown","metadata":{"cell_id":"8a081778cc704fc6bed05393a5419327","deepnote_cell_type":"markdown"},"source":["## 1.5 Visualizaciones (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n","</p>\n","\n","\n","Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n","\n","A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n","\n","- Gráfico de historial de optimización\n","- Gráfico de coordenadas paralelas\n","- Gráfico de importancia de hiperparámetros\n","\n","Comente sus resultados: ¿Desde qué *trial* se empiezan a observar mejoras notables en sus resultados? ¿Qué tendencias puede observar a partir del gráfico de coordenadas paralelas? ¿Cuáles son los hiperparámetros con mayor importancia para la optimización de su modelo?"]},{"cell_type":"code","execution_count":12,"metadata":{"cell_id":"0e706dc9a8d946eda7a9eb1f0463c6d7","deepnote_cell_type":"code"},"outputs":[],"source":["# Inserte su código acá"]},{"cell_type":"markdown","metadata":{"cell_id":"ac8a20f445d045a3becf1a518d410a7d","deepnote_cell_type":"markdown"},"source":["## 1.6 Síntesis de resultados (0.3)\n","\n","Finalmente, genere una tabla resumen del MAE obtenido en los 5 modelos entrenados (desde Baseline hasta XGBoost con Constraints, Optuna y Prunning) y compare sus resultados. ¿Qué modelo obtiene el mejor rendimiento? \n","\n","Por último, cargue el mejor modelo, prediga sobre el conjunto de test y reporte su MAE. ¿Existen diferencias con respecto a las métricas obtenidas en el conjunto de validación? ¿Porqué puede ocurrir esto?"]},{"cell_type":"markdown","metadata":{"cell_id":"5c4654d12037494fbd385b4dc6bd1059","deepnote_cell_type":"markdown"},"source":["# Conclusión\n","Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n","</p>"]},{"cell_type":"markdown","metadata":{"cell_id":"5025de06759f4903a26916c80323bf25","deepnote_cell_type":"markdown"},"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"f63d38450a6b464c9bb6385cf11db4d9","deepnote_persisted_session":{"createdAt":"2023-11-09T16:18:30.203Z"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
