{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"b5c0d2440b3e4995a794ded565213150","deepnote_cell_type":"markdown"},"source":["<h1><center>Laboratorio 9: Optimizaci칩n de modelos 游눮</center></h1>\n","\n","<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos</strong></center>"]},{"cell_type":"markdown","metadata":{"cell_id":"bfb94b9656f145ad83e81b75d218cb70","deepnote_cell_type":"markdown"},"source":["### Cuerpo Docente:\n","\n","- Profesor: Ignacio Meza, Gabriel Iturra\n","- Auxiliar: Sebasti치n Tinoco\n","- Ayudante: Arturo Lazcano, Angelo Mu침oz"]},{"cell_type":"markdown","metadata":{"cell_id":"b1b537fdd27c43909a49d3476ce64d91","deepnote_cell_type":"markdown"},"source":["### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados\n","\n","- Nombre de alumno 1: Nicol치s Acevedo\n","- Nombre de alumno 2: Fabiola Pizarro\n"]},{"cell_type":"markdown","metadata":{"cell_id":"b7dbdd30ab544cb8a8afe00648a586ae","deepnote_cell_type":"markdown"},"source":["## Temas a tratar\n","\n","- Predicci칩n de demanda usando `xgboost`\n","- B칰squeda del modelo 칩ptimo de clasificaci칩n usando `optuna`\n","- Uso de pipelines.\n","\n","## Reglas:\n","\n","- **Grupos de 2 personas**\n","- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n","- Prohibidas las copias. \n","- Pueden usar cualquer material del curso que estimen conveniente.\n","\n","### Objetivos principales del laboratorio\n","\n","- Optimizar modelos usando `optuna`\n","- Recurrir a t칠cnicas de *prunning*\n","- Forzar el aprendizaje de relaciones entre variables mediante *constraints*\n","- Fijar un pipeline con un modelo base que luego se ir치 optimizando.\n","\n","El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."]},{"cell_type":"markdown","metadata":{"cell_id":"f38c8342f5164aa992a97488dd5590bf","deepnote_cell_type":"markdown"},"source":["### **Link de repositorio de GitHub:** `https://github.com/nicoacevedor/MDS7202`"]},{"cell_type":"markdown","metadata":{"cell_id":"f1c73babb7f74af588a4fa6ae14829e0","deepnote_cell_type":"markdown"},"source":["# Importamos librerias 칰tiles"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"51afe4d2df42442b9e5402ffece60ead","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4957,"execution_start":1699544354044,"source_hash":null},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from datetime import datetime\n","import joblib\n","\n","import numpy as np\n","import pandas as pd\n","import optuna\n","from optuna.samplers import TPESampler\n","from pandas.api.types import is_datetime64_any_dtype as is_datetime\n","from sklearn.compose import ColumnTransformer\n","from sklearn.dummy import DummyRegressor\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n","import xgboost as xgb"]},{"cell_type":"markdown","metadata":{"cell_id":"44d227389a734ac59189c5e0005bc68a","deepnote_cell_type":"markdown"},"source":["# 1. El emprendimiento de Fiu\n","\n","Tras liderar de manera exitosa la implementaci칩n de un proyecto de ciencia de datos para caracterizar los datos generados en Santiago 2023, el misterioso corp칩reo **Fiu** se anima y decide levantar su propio negocio de consultor칤a en machine learning. Tras varias e intensas negociaciones, Fiu logra encontrar su *primera chamba*: predecir la demanda (cantidad de venta) de una famosa productora de bebidas de calibre mundial. Como usted tuvo un rendimiento sobresaliente en el proyecto de caracterizaci칩n de datos, Fiu lo contrata como *data scientist* de su emprendimiento.\n","\n","Para este laboratorio deben trabajar con los datos `sales.csv` subidos a u-cursos, el cual contiene una muestra de ventas de la empresa para diferentes productos en un determinado tiempo.\n","\n","Para comenzar, cargue el dataset se침alado y visualice a trav칠s de un `.head` los atributos que posee el dataset.\n","\n","<i><p align=\"center\">Fiu siendo felicitado por su excelente desempe침o en el proyecto de caracterizaci칩n de datos</p></i>\n","<p align=\"center\">\n","  <img src=\"https://media-front.elmostrador.cl/2023/09/A_UNO_1506411_2440e.jpg\">\n","</p>"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"2f9c82d204b14515ad27ae07e0b77702","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":92,"execution_start":1699544359006,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 7456 entries, 0 to 7455\n","Data columns (total 12 columns):\n"," #   Column     Non-Null Count  Dtype         \n","---  ------     --------------  -----         \n"," 0   id         7456 non-null   int32         \n"," 1   date       7456 non-null   datetime64[ns]\n"," 2   city       7456 non-null   category      \n"," 3   lat        7456 non-null   float64       \n"," 4   long       7456 non-null   float64       \n"," 5   pop        7456 non-null   int32         \n"," 6   shop       7456 non-null   category      \n"," 7   brand      7456 non-null   category      \n"," 8   container  7456 non-null   category      \n"," 9   capacity   7456 non-null   category      \n"," 10  price      7456 non-null   float64       \n"," 11  quantity   7456 non-null   int32         \n","dtypes: category(5), datetime64[ns](1), float64(3), int32(3)\n","memory usage: 357.8 KB\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Rocky\\AppData\\Local\\Temp\\ipykernel_14396\\2241364177.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  df = df.astype(df_types)\n"]}],"source":["df = pd.read_csv('sales.csv')\n","df_types = {\n","    'id': int,\n","    'date': 'datetime64[ns]',\n","    'city': 'category',\n","    'lat': float,\n","    'long': float,\n","    'pop': int,\n","    'shop': 'category',\n","    'brand': 'category',\n","    'container': 'category',\n","    'capacity': 'category',\n","    'price': float,\n","    'quantity': int\n","}\n","df = df.astype(df_types)\n","df.info()\n"]},{"cell_type":"markdown","metadata":{"cell_id":"b50db6f2cb804932ae3f9e5748a6ea61","deepnote_cell_type":"markdown"},"source":["## 1.1 Generando un Baseline (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/O-lan6TkadUAAAAC/what-i-wnna-do-after-a-baseline.gif\">\n","</p>\n","\n","Antes de entrenar un algoritmo, usted recuerda los apuntes de su mag칤ster en ciencia de datos y recuerda que debe seguir una serie de *buenas pr치cticas* para entrenar correcta y debidamente su modelo. Despu칠s de un par de vueltas, llega a las siguientes tareas:\n","\n","1. Separe los datos en conjuntos de train (70%), validation (20%) y test (10%). Fije una semilla para controlar la aleatoriedad.\n","2. Implemente un `FunctionTransformer` para extraer el d칤a, mes y a침o de la variable `date`. Guarde estas variables en el formato categorical de pandas.\n","3. Implemente un `ColumnTransformer` para procesar de manera adecuada los datos num칠ricos y categ칩ricos. Use `OneHotEncoder` para las variables categ칩ricas.\n","4. Guarde los pasos anteriores en un `Pipeline`, dejando como 칰ltimo paso el regresor `DummyRegressor` para generar predicciones en base a promedios.\n","5. Entrene el pipeline anterior y reporte la m칠trica `mean_absolute_error` sobre los datos de validaci칩n. 쮺칩mo se interpreta esta m칠trica para el contexto del negocio?\n","6. Finalmente, vuelva a entrenar el `Pipeline` pero esta vez usando `XGBRegressor` como modelo **utilizando los par치metros por default**. 쮺칩mo cambia el MAE al implementar este algoritmo? 쮼s mejor o peor que el `DummyRegressor`?\n","7. Guarde ambos modelos en un archivo .pkl (uno cada uno)"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"1482c992d9494e5582b23dbd3431dbfd","deepnote_cell_type":"code"},"outputs":[],"source":["gen = np.random.default_rng(seed=42)\n","data = pd.DataFrame(gen.permutation(df), columns=df.columns)\n","data = data.astype(df_types)\n","n = data.shape[0]\n","\n","train_size, val_size = int(0.7*n), int(0.2*n)\n","train_data = data[:train_size]\n","validation_data = data[train_size:train_size+val_size]\n","test_data = data[train_size+val_size:]"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def datetime_to_categorical(df: pd.DataFrame):\n","    df_in = df.copy()\n","    datetime_column = ''\n","    for col in df.columns:\n","        if is_datetime(df[col]):\n","            datetime_column = col\n","    if datetime_column == '':\n","        raise ValueError(\"Los datos no poseen ninguna columna con formato fecha\")\n","\n","    df_in['day'] = df_in[datetime_column].dt.day\n","    df_in['day'] = df_in['day'].astype('category')\n","    df_in['month'] = df_in[datetime_column].dt.month\n","    df_in['month'] = df_in['month'].astype('category')\n","    df_in['year'] = df_in[datetime_column].dt.year\n","    df_in['year'] = df_in['year'].astype('category')\n","    df_in.drop([datetime_column], axis=1, inplace=True)\n","    return df_in"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["numeric_cols = ['id', 'lat', 'long', 'pop', 'price', 'quantity']\n","categorical_cols = list(set(df.columns) - (set(numeric_cols).union({'date'})))\n","categorical_cols = list(set(categorical_cols) | set(['day', 'month', 'year']))\n","\n","transformer = FunctionTransformer(datetime_to_categorical)\n","\n","scaler = ColumnTransformer([\n","    (\"NumericScaler\", MinMaxScaler(), numeric_cols),\n","    (\"CategoricalEncoder\", OneHotEncoder(sparse_output=False), categorical_cols)\n","], remainder=\"drop\", verbose_feature_names_out=False)\n","scaler.set_output(transform='pandas')\n","\n","pipeline_dummy = Pipeline([\n","    ('Transformer', transformer),\n","    ('Scaler', scaler),\n","    ('Regressor', DummyRegressor())\n","])\n","\n","pipeline_xgb = Pipeline([\n","    ('Transformer', transformer),\n","    ('Scaler', scaler),\n","    ('Regressor', xgb.XGBRegressor())\n","])\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El error absoluto medio es de 13439.757\n"]}],"source":["X_train = train_data[list(set(data.columns) - set('quantity'))]\n","X_validation = validation_data[list(set(data.columns) - set('quantity'))]\n","X_test = test_data[list(set(data.columns) - set('quantity'))]\n","y_train = train_data['quantity']\n","y_validation = validation_data['quantity']\n","y_test = test_data['quantity']\n","\n","pipeline_dummy.fit(X=X_train, y=y_train)\n","joblib.dump(pipeline_dummy, \"pipeline_dummy.pkl\")\n","y_pred_dummy = pipeline_dummy.predict(X_validation)\n","\n","print(f\"El error absoluto medio es de {mean_absolute_error(y_validation, y_pred_dummy):.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["Al ser un valor tan alto, esto nos dice que la predicci칩n no es buena. En el contexto de las ventas, esto indica que las ventas tienen muchos valores distintos, y que no son similares a la media de todas las ventas. Esto tiene sentido ya que la cantidad de ventas depende por lo menos del pa칤s, del producto y del precio."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El error absoluto medio es de 150.760\n"]}],"source":["pipeline_xgb.fit(X=X_train, y=y_train)\n","y_pred_xgb = pipeline_xgb.predict(X_validation)\n","joblib.dump(pipeline_xgb, \"pipeline_xgb.pkl\")\n","print(f\"El error absoluto medio es de {mean_absolute_error(y_validation, y_pred_xgb):.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["Este resultado es mucho mejor, ya que el error absoluto medio es un 1% del valor anterior. Esto indica que la predicci칩n hecha por XGBRegressor es mucho m치s cercana a la realidad que solo tomar la media de los datos."]},{"cell_type":"markdown","metadata":{"cell_id":"7e17e46063774ec28226fe300d42ffe0","deepnote_cell_type":"markdown"},"source":["## 1.2 Forzando relaciones entre par치metros con XGBoost (1.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://64.media.tumblr.com/14cc45f9610a6ee341a45fd0d68f4dde/20d11b36022bca7b-bf/s640x960/67ab1db12ff73a530f649ac455c000945d99c0d6.gif\">\n","</p>\n","\n","Un colega aficionado a la econom칤a le *sopla* que la demanda guarda una relaci칩n inversa con el precio del producto. Motivado para impresionar al querido corp칩reo, se propone hacer uso de esta informaci칩n para mejorar su modelo.\n","\n","Vuelva a entrenar el `Pipeline`, pero esta vez forzando una relaci칩n mon칩tona negativa entre el precio y la cantidad. Luego, vuelva a reportar el `MAE` sobre el conjunto de validaci칩n. 쮺칩mo cambia el error al incluir esta relaci칩n? 쯊en칤a raz칩n su amigo?\n","\n","Nuevamente, guarde su modelo en un archivo .pkl\n","\n","Nota: Para realizar esta parte, debe apoyarse en la siguiente <a href = https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html>documentaci칩n</a>.\n","\n","Hint: Para implementar el constraint, se le sugiere hacerlo especificando el nombre de la variable. De ser as칤, probablemente le sea 칰til **mantener el formato de pandas** antes del step de entrenamiento."]},{"cell_type":"code","execution_count":8,"metadata":{"cell_id":"f469f3b572be434191d2d5c3f11b20d2","deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":["El error absoluto medio es de 151.987\n"]}],"source":["pipeline_xgb_constraint = Pipeline([\n","    ('Transformer', transformer),\n","    ('Scaler', scaler),\n","    ('Regressor', xgb.XGBRegressor(monotone_constraints={'price': -1}))\n","])\n","pipeline_xgb_constraint.fit(X=X_train, y=y_train)\n","joblib.dump(pipeline_xgb_constraint, \"pipeline_xgb_constraint.pkl\")\n","y_pred_constraint = pipeline_xgb_constraint.predict(X_validation)\n","print(f\"El error absoluto medio es de {mean_absolute_error(y_validation, y_pred_constraint):.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["El error aumenta un poco, no mucho pero aumenta. Esto puede deberse a que anteriormente el modelo ya aprendi칩 la relaci칩n inversa entre el precio y el producto, por lo que la variaci칩n es poca. Adem치s, si bien existe esta relaci칩n inversa, eso no considera otros factores como el precio por pa칤s, que aunque este aumente, puede que en proporci칩n el producto sea m치s barato, por lo que en esa situaci칩n la relaci칩n ya no es completamente inversa.\n","\n","Por lo tanto, el amigo no tiene toda la raz칩n."]},{"cell_type":"markdown","metadata":{"cell_id":"e59ef80ed20b4de8921f24da74e87374","deepnote_cell_type":"markdown"},"source":["## 1.3 Optimizaci칩n de Hiperpar치metros con Optuna (2.0 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/fmNdyGN4z5kAAAAi/hacking-lucy.gif\">\n","</p>\n","\n","Luego de presentarle sus resultados, Fiu le pregunta si es posible mejorar *aun m치s* su modelo. En particular, le comenta de la optimizaci칩n de hiperpar치metros con metodolog칤as bayesianas a trav칠s del paquete `optuna`. Como usted es un aficionado al entrenamiento de modelos de ML, se propone implementar la descabellada idea de su jefe.\n","\n","A partir de la mejor configuraci칩n obtenida en la secci칩n anterior, utilice `optuna` para optimizar sus hiperpar치metros. En particular, se le pide:\n","\n","- Fijar una semilla en las instancias necesarias para garantizar la reproducibilidad de resultados\n","- Utilice `TPESampler` como m칠todo de muestreo\n","- De `XGBRegressor`, optimice los siguientes hiperpar치metros:\n","    - `learning_rate` buscando valores flotantes en el rango (0.001, 0.1)\n","    - `n_estimators` buscando valores enteros en el rango (50, 1000)\n","    - `max_depth` buscando valores enteros en el rango (3, 10)\n","    - `max_leaves` buscando valores enteros en el rango (0, 100)\n","    - `min_child_weight` buscando valores enteros en el rango (1, 5)\n","    - `reg_alpha` buscando valores flotantes en el rango (0, 1)\n","    - `reg_lambda` buscando valores flotantes en el rango (0, 1)\n","- De `OneHotEncoder`, optimice el hiperpar치metro `min_frequency` buscando el mejor valor flotante en el rango (0.0, 1.0)\n","- Explique cada hiperpar치metro y su rol en el modelo. 쮿acen sentido los rangos de optimizaci칩n indicados?\n","- Fije el tiempo de entrenamiento a 5 minutos\n","- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto?\n","- Guardar su modelo en un archivo .pkl"]},{"cell_type":"markdown","metadata":{},"source":["Los hiperpar치metros del `XGBRegressor` son los siguientes:\n","- `learning_rate`: Factor de aprendizaje del modelo\n","- `n_estimators`: N칰mero de 치rboles generados\n","- `max_depth`: M치xima profundidad de cada 치rbol\n","- `max_leaves`: N칰mero m치ximo de hojas de cada 치rbol\n","- `min_child_weight`: Umbral para el cual un nodo se deja de dividir si la cantidad de datos baja de este\n","- `reg_alpha`: Factor de regularizaci칩n para dimensiones altas\n","- `reg_lambda`: Factor de regularizaci칩n para reducir overfitting\n","\n","El hiperpar치metro del `OneHotEncoder`\n","- `min_frequency`: M칤nima frecuencia relativa para una etiqueta ser considerada categor칤a"]},{"cell_type":"code","execution_count":9,"metadata":{"cell_id":"de5914621cc64cb0b1bacb9ff565a97e","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["Best trial: 872. Best value: 126.557:  100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 05:00/05:00\n"]}],"source":["optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","random_seed = 42\n","\n","study = optuna.create_study(\n","    sampler=TPESampler(seed=random_seed),\n","    direction='minimize',\n","    study_name=\"pipeline\"\n",")\n","\n","def objective(trial: optuna.Trial, data, target, validation, val_target, random_seed=42):\n","    regressor_params = {\n","        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n","        'n_estimators': trial.suggest_int('n_estimators', 50, 100),\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'max_leaves': trial.suggest_int('max_leaves', 0, 100),\n","        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n","        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n","        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)\n","    }\n","    numeric_cols = ['id', 'lat', 'long', 'pop', 'price', 'quantity']\n","    categorical_cols = list(set(data.columns) - (set(numeric_cols).union({'date'})))\n","    categorical_cols = list(set(categorical_cols) | set(['day', 'month', 'year']))\n","\n","    transformer = FunctionTransformer(datetime_to_categorical)\n","\n","    min_frequency = trial.suggest_float('min_frequency', 0, 1)\n","    scaler = ColumnTransformer([\n","        (\"NumericScaler\", MinMaxScaler(), numeric_cols),\n","        (\"CategoricalEncoder\", OneHotEncoder(sparse_output=False, min_frequency=min_frequency), categorical_cols)\n","    ], remainder=\"drop\", verbose_feature_names_out=False)\n","    scaler.set_output(transform='pandas')\n","\n","    regressor = xgb.XGBRegressor(**regressor_params)\n","\n","    pipeline = Pipeline([\n","        ('Transformer', transformer),\n","        ('Scaler', scaler),\n","        ('Regressor', regressor), \n","    ])\n","\n","    pipeline.fit(X=data, y=target)\n","    y_pred = pipeline.predict(X=validation)\n","    return mean_absolute_error(val_target, y_pred)\n","\n","\n","study.optimize(\n","    lambda trial: objective(trial, X_train, y_train, X_validation, y_validation),\n","    timeout=5*60,\n","    show_progress_bar=True\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["N칰mero de trials: 1072\n","MAE: 126.557\n","\n","Mejores par치metros:\n","--------------------\n","learning_rate: 0.082\n","n_estimators: 97.000\n","max_depth: 5.000\n","max_leaves: 25.000\n","min_child_weight: 1.000\n","reg_alpha: 0.149\n","reg_lambda: 0.111\n","min_frequency: 0.467\n"]}],"source":["min_frequency_opt = study.best_params.pop('min_frequency')\n","\n","scaler = ColumnTransformer([\n","    (\"NumericScaler\", MinMaxScaler(), numeric_cols),\n","    (\"CategoricalEncoder\", OneHotEncoder(sparse_output=False, min_frequency=min_frequency_opt), categorical_cols)\n","], remainder=\"drop\", verbose_feature_names_out=False)\n","scaler.set_output(transform='pandas')\n","\n","optimized_pipeline = Pipeline([\n","    ('Transformer', transformer),\n","    ('Scaler', scaler),\n","    ('Regressor', xgb.XGBRegressor(random_seed=42, **study.best_params))\n","])\n","joblib.dump(optimized_pipeline, \"optimized_pipeline.pkl\")\n","\n","print(f\"N칰mero de trials: {len(study.trials)}\")\n","print(f\"MAE: {study.best_value:.3f}\")\n","print(\"\\nMejores par치metros:\\n--------------------\")\n","for key, value in study.best_params.items():\n","    print(f\"{key}: {value:.3f}\")"]},{"cell_type":"markdown","metadata":{},"source":["El `MAE` es menor al encontrado en la secci칩n anterior, lo que se debe a que se est치 trabajando con valores mucho m치s 칩ptimos de los hiperpar치metros, en cambio antes se trabajaba con los valores por defecto que, si bien dan un resultado m치s o menos bueno, no es el mejor. Por lo tanto, al haber reducido el `MAE`, vemos que el nuevo modelo optimizado es mejor que el de la secci칩n anterior."]},{"cell_type":"markdown","metadata":{"cell_id":"5195ccfc37e044ad9453f6eb2754f631","deepnote_cell_type":"markdown"},"source":["## 1.4 Optimizaci칩n de Hiperpar치metros con Optuna y Prunners (1.7)\n","\n","<p align=\"center\">\n","  <img src=\"https://i.pinimg.com/originals/90/16/f9/9016f919c2259f3d0e8fe465049638a7.gif\">\n","</p>\n","\n","Despu칠s de optimizar el rendimiento de su modelo varias veces, Fiu le pregunta si no es posible optimizar el entrenamiento del modelo en s칤 mismo. Despu칠s de leer un par de post de personas de dudosa reputaci칩n en la *deepweb*, usted llega a la conclusi칩n que puede cumplir este objetivo mediante la implementaci칩n de **Prunning**.\n","\n","Vuelva a optimizar los mismos hiperpar치metros que la secci칩n pasada, pero esta vez utilizando **Prunning** en la optimizaci칩n. En particular, usted debe:\n","\n","- Responder: 쯈u칠 es prunning? 쮻e qu칠 forma deber칤a impactar en el entrenamiento?\n","- Utilizar `optuna.integration.XGBoostPruningCallback` como m칠todo de **Prunning**\n","- Fijar nuevamente el tiempo de entrenamiento a 5 minutos\n","- Reportar el n칰mero de *trials*, el `MAE` y los mejores hiperpar치metros encontrados. 쮺칩mo cambian sus resultados con respecto a la secci칩n anterior? 쮸 qu칠 se puede deber esto?\n","- Guardar su modelo en un archivo .pkl\n","\n","Nota: Si quieren silenciar los prints obtenidos en el prunning, pueden hacerlo mediante el siguiente comando:\n","\n","```\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","```\n","\n","De implementar la opci칩n anterior, pueden especificar `show_progress_bar = True` en el m칠todo `optimize` para *m치s sabor*.\n","\n","Hint: Si quieren especificar par치metros del m칠todo .fit() del modelo a trav칠s del pipeline, pueden hacerlo por medio de la siguiente sintaxis: `pipeline.fit(stepmodelo__parametro = valor)`\n","\n","Hint2: Este <a href = https://stackoverflow.com/questions/40329576/sklearn-pass-fit-parameters-to-xgboost-in-pipeline>enlace</a> les puede ser de ayuda en su implementaci칩n"]},{"cell_type":"code","execution_count":20,"metadata":{"cell_id":"eeaa967cd8f6426d8c54f276c17dce79","deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":["   0%|          | 00:00/05:00"]},{"name":"stdout","output_type":"stream","text":["[0]\tvalidation_0-mae:12929.58351\n","[1]\tvalidation_0-mae:12439.61955\n","[2]\tvalidation_0-mae:11967.95412\n","[3]\tvalidation_0-mae:11514.05199\n","[4]\tvalidation_0-mae:11076.83867\n","[5]\tvalidation_0-mae:10656.75833\n","[6]\tvalidation_0-mae:10253.09367\n","[7]\tvalidation_0-mae:9863.58898\n","[8]\tvalidation_0-mae:9490.42122\n","[9]\tvalidation_0-mae:9130.28326\n","[10]\tvalidation_0-mae:8783.58811\n","[11]\tvalidation_0-mae:8451.37023\n","[12]\tvalidation_0-mae:8130.44730\n","[13]\tvalidation_0-mae:7821.96862\n","[14]\tvalidation_0-mae:7525.70140\n","[15]\tvalidation_0-mae:7241.09228\n","[16]\tvalidation_0-mae:6966.15285\n","[17]\tvalidation_0-mae:6702.22867\n","[18]\tvalidation_0-mae:6447.97666\n","[19]\tvalidation_0-mae:6204.14580\n","[20]\tvalidation_0-mae:5969.64566\n","[21]\tvalidation_0-mae:5743.40575\n","[22]\tvalidation_0-mae:5525.83989\n","[23]\tvalidation_0-mae:5316.55916\n","[24]\tvalidation_0-mae:5115.11822\n","[25]\tvalidation_0-mae:4921.75714\n","[26]\tvalidation_0-mae:4735.67670\n","[27]\tvalidation_0-mae:4556.88736\n","[28]\tvalidation_0-mae:4384.83296\n","[29]\tvalidation_0-mae:4219.27736\n","[30]\tvalidation_0-mae:4059.74337\n","[31]\tvalidation_0-mae:3906.56417\n","[32]\tvalidation_0-mae:3758.78135\n","[33]\tvalidation_0-mae:3616.92393\n","[34]\tvalidation_0-mae:3480.21269\n","[35]\tvalidation_0-mae:3348.98235\n","[36]\tvalidation_0-mae:3222.76328\n","[37]\tvalidation_0-mae:3101.00014\n","[38]\tvalidation_0-mae:2984.32885\n","[39]\tvalidation_0-mae:2871.76721\n","[40]\tvalidation_0-mae:2763.65600\n","[41]\tvalidation_0-mae:2659.68117\n","[42]\tvalidation_0-mae:2559.60263\n","[43]\tvalidation_0-mae:2463.32860\n","[44]\tvalidation_0-mae:2370.75280\n","[45]\tvalidation_0-mae:2281.53292\n","[46]\tvalidation_0-mae:2195.86869\n","[47]\tvalidation_0-mae:2113.18655\n","[48]\tvalidation_0-mae:2033.64121\n","[49]\tvalidation_0-mae:1957.28130\n","[50]\tvalidation_0-mae:1883.79974\n","[51]\tvalidation_0-mae:1812.96264\n","[52]\tvalidation_0-mae:1744.97940\n","[53]\tvalidation_0-mae:1679.49088\n","[54]\tvalidation_0-mae:1616.54194\n","[55]\tvalidation_0-mae:1556.06630\n","[56]\tvalidation_0-mae:1497.95175\n","[57]\tvalidation_0-mae:1442.00511\n","[58]\tvalidation_0-mae:1388.30914\n","[59]\tvalidation_0-mae:1336.32726\n","[60]\tvalidation_0-mae:1286.63880\n","[61]\tvalidation_0-mae:1238.86014\n","[62]\tvalidation_0-mae:1192.91900\n","[63]\tvalidation_0-mae:1148.58114\n","[64]\tvalidation_0-mae:1106.02023\n","[65]\tvalidation_0-mae:1065.09959\n","[66]\tvalidation_0-mae:1025.44421\n","[67]\tvalidation_0-mae:987.57234\n","[68]\tvalidation_0-mae:951.24061\n","[69]\tvalidation_0-mae:916.03981\n","[70]\tvalidation_0-mae:882.19793\n","[71]\tvalidation_0-mae:849.68559\n","[72]\tvalidation_0-mae:818.55594\n","[73]\tvalidation_0-mae:788.57388\n","[74]\tvalidation_0-mae:759.68036\n","[75]\tvalidation_0-mae:731.88672\n","[76]\tvalidation_0-mae:704.93181\n","[77]\tvalidation_0-mae:679.68319\n","[78]\tvalidation_0-mae:655.34445\n","[79]\tvalidation_0-mae:631.73441\n","[80]\tvalidation_0-mae:608.90672\n","[81]\tvalidation_0-mae:586.95616\n","[82]\tvalidation_0-mae:565.91291\n","[83]\tvalidation_0-mae:546.02105\n","[84]\tvalidation_0-mae:526.40528\n","[85]\tvalidation_0-mae:507.90075\n","[86]\tvalidation_0-mae:489.77556\n","[87]\tvalidation_0-mae:472.57144\n","[88]\tvalidation_0-mae:455.99219\n","[89]\tvalidation_0-mae:440.34026\n","[90]\tvalidation_0-mae:425.03821\n","[91]\tvalidation_0-mae:410.56433\n","[92]\tvalidation_0-mae:396.66370\n","[93]\tvalidation_0-mae:383.21426\n","[94]\tvalidation_0-mae:370.27658\n","[95]\tvalidation_0-mae:357.73191\n","[96]\tvalidation_0-mae:345.96610\n","[97]\tvalidation_0-mae:334.81981\n"]},{"name":"stderr","output_type":"stream","text":["   0%|          | 00:00/05:00"]},{"name":"stdout","output_type":"stream","text":["[W 2023-11-17 10:55:44,531] Trial 0 failed with parameters: {'learning_rate': 0.03807947176588889, 'n_estimators': 98, 'max_depth': 8, 'max_leaves': 60, 'min_child_weight': 1, 'reg_alpha': 0.15599452033620265, 'reg_lambda': 0.05808361216819946, 'min_frequency': 0.8661761457749352} because of the following error: ValueError('Los datos no poseen ninguna columna con formato fecha').\n","Traceback (most recent call last):\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","                      ^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Temp\\ipykernel_14396\\334774914.py\", line 65, in <lambda>\n","    lambda trial: objective(trial, X_train, y_train, X_validation, y_validation),\n","                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Temp\\ipykernel_14396\\334774914.py\", line 60, in objective\n","    y_pred = pipeline.predict(X=validation_scaled)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py\", line 480, in predict\n","    Xt = transform.transform(Xt)\n","         ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n","    data_to_wrap = f(self, X, *args, **kwargs)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 238, in transform\n","    return self._transform(X, func=self.func, kw_args=self.kw_args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 310, in _transform\n","    return func(X, **(kw_args if kw_args else {}))\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\Rocky\\AppData\\Local\\Temp\\ipykernel_14396\\2374987663.py\", line 8, in datetime_to_categorical\n","    raise ValueError(\"Los datos no poseen ninguna columna con formato fecha\")\n","ValueError: Los datos no poseen ninguna columna con formato fecha\n","[W 2023-11-17 10:55:44,535] Trial 0 failed with value None.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"ename":"ValueError","evalue":"Los datos no poseen ninguna columna con formato fecha","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Rocky\\Documents\\GitHub\\MDS7202\\lab9\\Lab9.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(X\u001b[39m=\u001b[39mvalidation_scaled)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mean_absolute_error(val_target, y_pred)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mlambda\u001b[39;49;00m trial: objective(trial, X_train, y_train, X_validation, y_validation),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     timeout\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m60\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m )\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n","\u001b[1;32mc:\\Users\\Rocky\\Documents\\GitHub\\MDS7202\\lab9\\Lab9.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mpredict(X\u001b[39m=\u001b[39mvalidation_scaled)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mean_absolute_error(val_target, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mlambda\u001b[39;00m trial: objective(trial, X_train, y_train, X_validation, y_validation),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     timeout\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m\u001b[39m*\u001b[39m\u001b[39m60\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     show_progress_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m )\n","\u001b[1;32mc:\\Users\\Rocky\\Documents\\GitHub\\MDS7202\\lab9\\Lab9.ipynb Cell 27\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m validation_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(validation_transformed)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m pipeline\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mdata, y\u001b[39m=\u001b[39mtarget, Regressor__eval_set\u001b[39m=\u001b[39m[(validation_scaled, val_target)])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m y_pred \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mpredict(X\u001b[39m=\u001b[39;49mvalidation_scaled)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mreturn\u001b[39;00m mean_absolute_error(val_target, y_pred)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\pipeline.py:480\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    478\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[0;32m    479\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 480\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[0;32m    481\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:238\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39m    Transformed input.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_input(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(X, func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, kw_args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkw_args)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:310\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[1;34m(self, X, func, kw_args)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[39mif\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m     func \u001b[39m=\u001b[39m _identity\n\u001b[1;32m--> 310\u001b[0m \u001b[39mreturn\u001b[39;00m func(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(kw_args \u001b[39mif\u001b[39;49;00m kw_args \u001b[39melse\u001b[39;49;00m {}))\n","\u001b[1;32mc:\\Users\\Rocky\\Documents\\GitHub\\MDS7202\\lab9\\Lab9.ipynb Cell 27\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         datetime_column \u001b[39m=\u001b[39m col\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m datetime_column \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLos datos no poseen ninguna columna con formato fecha\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df_in[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_in[datetime_column]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mday\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Rocky/Documents/GitHub/MDS7202/lab9/Lab9.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df_in[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_in[\u001b[39m'\u001b[39m\u001b[39mday\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[1;31mValueError\u001b[0m: Los datos no poseen ninguna columna con formato fecha"]}],"source":["optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","random_seed = 42\n","\n","study = optuna.create_study(\n","    sampler=TPESampler(seed=random_seed),\n","    direction='minimize',\n","    study_name=\"pipeline_pruning\"\n",")\n","\n","def objective(trial: optuna.Trial, data, target, validation, val_target, random_seed=42):\n","    regressor_params = {\n","        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n","        'n_estimators': trial.suggest_int('n_estimators', 50, 100),\n","        'max_depth': trial.suggest_int('max_depth', 3, 10),\n","        'max_leaves': trial.suggest_int('max_leaves', 0, 100),\n","        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n","        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n","        'reg_lambda': trial.suggest_float('reg_lambda', 0, 1)\n","    }\n","        \n","    numeric_cols = ['id', 'lat', 'long', 'pop', 'price', 'quantity']\n","    categorical_cols = list(set(data.columns) - (set(numeric_cols).union({'date'})))\n","    categorical_cols = list(set(categorical_cols) | set(['day', 'month', 'year']))\n","    \n","    transformer = FunctionTransformer(datetime_to_categorical)\n","\n","    min_frequency = trial.suggest_float('min_frequency', 0, 1)\n","    scaler = ColumnTransformer([\n","        (\"NumericScaler\", MinMaxScaler(), numeric_cols),\n","        (\"CategoricalEncoder\", OneHotEncoder(sparse_output=False, min_frequency=min_frequency), categorical_cols)\n","    ], remainder=\"drop\", verbose_feature_names_out=False)\n","    scaler.set_output(transform='pandas')\n","\n","    pruning_callback = optuna.integration.XGBoostPruningCallback(\n","        trial, observation_key=\"validation_0-mae\"\n","    )\n","\n","    regressor = xgb.XGBRegressor(**regressor_params, eval_metric='mae',\n","                                early_stopping_rounds=10,\n","                                callbacks=[pruning_callback])\n","\n","    # Habilitar la opci칩n enable_categorical=True\n","    # regressor.set_params(enable_categorical=True)\n","\n","    pipeline = Pipeline([\n","        ('Transformer', transformer),\n","        ('Scaler', scaler),\n","        ('Regressor', regressor), \n","    ])\n","\n","    # Ajustar el ColumnTransformer con los datos de entrenamiento\n","    data_transformed = transformer.transform(data)\n","    scaler.fit(data_transformed)\n","    # Preprocesamiento de los datos de validaci칩n\n","    validation_transformed = transformer.transform(validation)\n","    validation_scaled = scaler.transform(validation_transformed)\n","\n","    pipeline.fit(X=data, y=target, Regressor__eval_set=[(validation_scaled, val_target)])\n","    y_pred = pipeline.predict(X=validation_scaled)\n","    return mean_absolute_error(val_target, y_pred)\n","\n","\n","study.optimize(\n","    lambda trial: objective(trial, X_train, y_train, X_validation, y_validation),\n","    timeout=5*60,\n","    show_progress_bar=True\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Prunning permite detener autom치ticamente las pruebas poco prometedoras en las primeras etapas del entrenamiento de un modelo, en otras palabras, se interrumpe el entrenamiento de un modelo si no muestra un rendimiento prometedor seg칰n una m칠trica espec칤fica. Esto deber칤a beneficiar el entrenamiento del modelo porque ayuda a evitar el sobreajuste y mejorar la eficiencia del proceso de b칰squeda de hiperpar치metros."]},{"cell_type":"markdown","metadata":{"cell_id":"8a081778cc704fc6bed05393a5419327","deepnote_cell_type":"markdown"},"source":["## 1.5 Visualizaciones (0.5 puntos)\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/F-LgB1xTebEAAAAd/look-at-this-graph-nickelback.gif\">\n","</p>\n","\n","\n","Satisfecho con su trabajo, Fiu le pregunta si es posible generar visualizaciones que permitan entender el entrenamiento de su modelo.\n","\n","A partir del siguiente <a href = https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html#visualization>enlace</a>, genere las siguientes visualizaciones:\n","\n","- Gr치fico de historial de optimizaci칩n\n","- Gr치fico de coordenadas paralelas\n","- Gr치fico de importancia de hiperpar치metros\n","\n","Comente sus resultados: 쮻esde qu칠 *trial* se empiezan a observar mejoras notables en sus resultados? 쯈u칠 tendencias puede observar a partir del gr치fico de coordenadas paralelas? 쮺u치les son los hiperpar치metros con mayor importancia para la optimizaci칩n de su modelo?"]},{"cell_type":"code","execution_count":12,"metadata":{"cell_id":"0e706dc9a8d946eda7a9eb1f0463c6d7","deepnote_cell_type":"code"},"outputs":[],"source":["# Inserte su c칩digo ac치"]},{"cell_type":"markdown","metadata":{"cell_id":"ac8a20f445d045a3becf1a518d410a7d","deepnote_cell_type":"markdown"},"source":["## 1.6 S칤ntesis de resultados (0.3)\n","\n","Finalmente, genere una tabla resumen del MAE obtenido en los 5 modelos entrenados (desde Baseline hasta XGBoost con Constraints, Optuna y Prunning) y compare sus resultados. 쯈u칠 modelo obtiene el mejor rendimiento? \n","\n","Por 칰ltimo, cargue el mejor modelo, prediga sobre el conjunto de test y reporte su MAE. 쮼xisten diferencias con respecto a las m칠tricas obtenidas en el conjunto de validaci칩n? 쯇orqu칠 puede ocurrir esto?"]},{"cell_type":"markdown","metadata":{"cell_id":"5c4654d12037494fbd385b4dc6bd1059","deepnote_cell_type":"markdown"},"source":["# Conclusi칩n\n","Eso ha sido todo para el lab de hoy, recuerden que el laboratorio tiene un plazo de entrega de una semana. Cualquier duda del laboratorio, no duden en contactarnos por mail o U-cursos.\n","\n","<p align=\"center\">\n","  <img src=\"https://media.tenor.com/8CT1AXElF_cAAAAC/gojo-satoru.gif\">\n","</p>"]},{"cell_type":"markdown","metadata":{"cell_id":"5025de06759f4903a26916c80323bf25","deepnote_cell_type":"markdown"},"source":[]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=87110296-876e-426f-b91d-aaf681223468' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"f63d38450a6b464c9bb6385cf11db4d9","deepnote_persisted_session":{"createdAt":"2023-11-09T16:18:30.203Z"},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
